# HMM-Segmentation
这个是我的练习随笔，用于记录学习NLP的过程。

中文分词通常包含： 1.规则分词 2.统计分词 3.混合分词

规则分词：基于规则的分词是一种机械的分词方法，主要通过维护词典，在切分语句时，将语句的每个字符串与词表中的词进行逐一匹配，找到则切分，否则不予切分。 这种分词方式又包含：正向最大匹配法、逆向最大匹配法和双向最大匹配法。 下面我主要讲讲正向最大匹配法的基本思想。首先我们假定词典中的最长词有i个汉字字符，则用被处理文档的当前字串中的前i个字作为匹配字段，查找字典。若字典中存在这样的 一个i字词，则匹配成功，因而匹配字段就被作为一个词切分出来。如果词典中找不到这样的一个i字词，则匹配失败，将匹配字段中的最后一个字去掉，对剩下的字串重新进行 匹配处理。如此进行下去，直到匹配成功，即且分出一个词或剩余字穿的长度为0为止，这样就完成了一轮匹配，然后取下一个i字字串进行匹配处理，直到文档被扫描完为止。

根据上述正向的，那么逆向最大匹配就很好理解。但是通常会发现采用逆向最大匹配的效果稍微好点。 我们要穿插讲个”汉语的偏正结构“的内容。 汉语中有很多例如”我的书、美丽的校园“等这类定中结构（我的、美丽的 是定语，书、校园是中心词语），还有一种是例如”狠狠地打、高兴地笑、瞎猜“等这 类状中结构的短语，上述就是常见的汉语偏正结构的两种类型。 因而，解释逆向最大匹配效果好的理由是汉语中偏正结构较多。我的理解是由于偏正结构多，往往后面的词更加重要，那么我们首先准备地切分出句子的主干结构成分， 对于我们理解整句话有更大的帮助。

下面我们就讲一下，隐马尔可夫模型。 它的主要思想就是将分词作为字在字串中的序列标注任务来实现的，其基本思路是：每个字在构造一个特定的词语时都占据一个确定的构词位置，同时规定每个字最多只有四个构词 位置，即B：词首、M：词中、E：词尾、S：单独成词。 同时引入两个假设条件：

观察独立性假设。 这个假设条件使每个时刻的输出仅仅与该时刻的状态有关这个条件成立。
齐次马尔可发假设。这个假设条件使得下一个时刻的输出标记只与上一时刻的标记有关条件成立。
